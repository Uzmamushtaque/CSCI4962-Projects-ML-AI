{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiBsgz1M1pQ3hZrphVmeK+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmamushtaque/CSCI4962-Projects-ML-AI/blob/main/Lecture_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Had3uxH2oQ"
      },
      "source": [
        "# Lecture 8\n",
        "\n",
        "# Topics for Today\n",
        "\n",
        "1. Word Embeddings\n",
        "2. Learning Word Embeddings\n",
        "3. Applications using word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GNXRT3V8z4i"
      },
      "source": [
        "# Word Embeddings\n",
        "\n",
        "A word embedding is a learned representation for text where words that have the same meaning have a similar representation.\n",
        "\n",
        "It is this approach to representing words and documents that may be considered one of the key breakthroughs of deep learning on challenging natural language processing problems.\n",
        "\n",
        "Word embeddings are in fact a class of techniques where individual words are represented as real-valued vectors in a predefined vector space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHhymtLuZLAm"
      },
      "source": [
        "# Visualizing Word Embeddings\n",
        "\n",
        "The new feature space created for words is high dimensional. There are algorithms that help us visualize these embeddings in lower dimensions:\n",
        "\n",
        "1. t-SNE: t-Distributed Stochastic Neighbor Embedding (t-SNE) is an unsupervised, non-linear technique primarily used for data exploration and visualizing high-dimensional data. In simpler terms, t-SNE gives you an intuition of how the data is arranged in a high-dimensional space. I\n",
        "\n",
        "\n",
        "[Link](https://projector.tensorflow.org/)"
      ]
    }
  ]
}