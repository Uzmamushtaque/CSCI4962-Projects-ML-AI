{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMV4pHJN/xD+ikAXKzwoGe9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmamushtaque/CSCI4962-Projects-ML-AI/blob/main/Lecture_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLIX4bhBZnGL"
      },
      "source": [
        "# Lecture 2\n",
        "\n",
        "## Today's Lecture\n",
        "\n",
        "1. Data manipulation and Pre-processing (Tensorflow, Numpy)\n",
        "2. Broadcasting\n",
        "3. Python numpy and pandas\n",
        "4. Logistic Regression using vectorization\n",
        "5. Gradient Descent (Optimization Algorithms)\n",
        "6. About Homework 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SBNbnAVOOx4"
      },
      "source": [
        "# Data manipulation\n",
        "\n",
        "Generally, there are two important things we need to do with data: \n",
        "(i) acquire them; and (ii) process them once they are inside the computer. \n",
        "\n",
        "[TensorFlow](https://www.tensorflow.org/) is an open-source end-to-end machine learning library for preprocessing data, modelling data and serving models (getting them into the hands of others).\n",
        "\n",
        "## Introduction to Tensors\n",
        "\n",
        "If you've ever used [NumPy](https://numpy.org/), tensors are kind of like NumPy arrays.\n",
        "\n",
        "You can consider of a tensor as a multi-dimensional numerical representation (also referred to as n-dimensional, where n can be any number) of something. Where something can be almost anything you can imagine:\n",
        "\n",
        "1. It could be numbers themselves (using tensors to represent the price of houses).\n",
        "2. It could be an image (using tensors to represent the pixels of an image).\n",
        "3. It could be text (using tensors to represent words).\n",
        "\n",
        "Or it could be some other form of information (or data) you want to represent with numbers.\n",
        "\n",
        "The main difference between tensors and NumPy arrays (also an n-dimensional array of numbers) is that tensors can be used on GPUs (graphical processing units) and TPUs (tensor processing units).\n",
        "\n",
        "The benefit of being able to run on GPUs and TPUs is faster computation, this means, if we wanted to find patterns in the numerical representations of our data, we can generally find them faster using GPUs and TPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ_0QkUPRYL-"
      },
      "source": [
        "Let us get started with Tensors.\n",
        "The first thing we'll do is import TensorFlow under the common alias tf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD4s6g3CT4oO",
        "outputId": "b33c77c9-0570-4915-e021-9bdeff1a1c7c"
      },
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__) # find the version number (should be 2.x+)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlTSivROVw8J"
      },
      "source": [
        "A tensor represents a (possibly multi-dimensional) array of numerical values. With one axis, a tensor corresponds (in math) to a vector. With two axes, a tensor corresponds to a matrix. Just as vectors generalize scalars, and matrices generalize vectors, we can build data structures with even more axes. Tensors give us a generic way of describing  n -dimensional arrays with an arbitrary number of axes. Vectors, for example, are first-order tensors, and matrices are second-order tensors. Let us create one tensor and then update its shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK9HgYwsWE4n",
        "outputId": "949b3780-fb1c-4384-e405-ce6555c5eb73"
      },
      "source": [
        "x = tf.range(12)\n",
        "x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiaF8sDqWMgr"
      },
      "source": [
        "We can access a tensorâ€™s shape (the length along each axis) by inspecting its shape property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZffiwfsWNo6",
        "outputId": "a5e6d2cf-12ec-40d4-de1d-83f245a973a4"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW_hzUJXWW2_"
      },
      "source": [
        "If we just want to know the total number of elements in a tensor, i.e., the product of all of the shape elements, we can inspect its size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K68icXaPWXn1",
        "outputId": "71d5d668-e4a2-439a-8116-195b3d8a90c7"
      },
      "source": [
        "tf.size(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=12>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7VBKpuaWew1"
      },
      "source": [
        "To change the shape of a tensor without altering either the number of elements or their values, we can invoke the reshape function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbOHkGsOWfi-",
        "outputId": "9d2db57e-3001-4301-ec68-58dbff9838d7"
      },
      "source": [
        "X = tf.reshape(x, (3, 4))\n",
        "X"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
              "array([[ 0,  1,  2,  3],\n",
              "       [ 4,  5,  6,  7],\n",
              "       [ 8,  9, 10, 11]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBNAVttPXAlo"
      },
      "source": [
        "Reshaping by manually specifying every dimension is unnecessary. If our target shape is a matrix with shape (height, width), then after we know the width, the height is given implicitly. Try calling x.reshape(-1, 4) or x.reshape(3, -1) for x above. Why do you think you get the result you are getting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Re4OXkpXM5q"
      },
      "source": [
        "Typically, we will want our matrices initialized either with zeros, ones, some other constants, or numbers randomly sampled from a specific distribution. We can create a tensor representing a tensor with all elements set to 0 and a shape of (2, 3, 4) as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5zOuvgRYANC",
        "outputId": "aab969fe-d29f-448e-ee86-57c55c749bae"
      },
      "source": [
        "tf.zeros((2, 3, 4))\n",
        "tf.ones((3,3,4))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 4), dtype=float32, numpy=\n",
              "array([[[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xtOlT7DYYeP"
      },
      "source": [
        "The following snippet creates a tensor with shape (3, 4). Each of its elements is randomly sampled from a standard Gaussian (normal) distribution with a mean of 0 and a standard deviation of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noTwc-3UYZXF",
        "outputId": "2423ce29-ee44-4931-ad2c-da5ab76e6cbd"
      },
      "source": [
        "tf.random.normal(shape=[3, 4])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[ 2.1004908 ,  2.1840525 ,  0.30567458, -0.26209387],\n",
              "       [ 0.3193501 , -0.37468615,  1.1882404 ,  0.01563128],\n",
              "       [ 0.01535824,  1.1524587 ,  0.44012707,  0.289547  ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxprfUGBY8d-",
        "outputId": "34d9e30b-b566-4880-b479-6f1ad859e43f"
      },
      "source": [
        "# An exact input for a tensor- Python List\n",
        "tf.constant([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
              "array([[2, 1, 4, 3],\n",
              "       [1, 2, 3, 4],\n",
              "       [4, 3, 2, 1]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNiy0EOh1AzG"
      },
      "source": [
        "# Operations\n",
        "\n",
        "All binary scalar operators are perform operations elementwise between arrays/matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtFcwS2A23o7",
        "outputId": "9b43bc50-afbe-4b27-fe7b-85e740ba171c"
      },
      "source": [
        "x = tf.constant([1.0, 2, 4, 8])\n",
        "y = tf.constant([2.0, 2, 2, 2])\n",
        "x + y, x - y, x * y, x / y, x**y  # The ** operator is exponentiation\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 3.,  4.,  6., 10.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1.,  0.,  2.,  6.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 2.,  4.,  8., 16.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5, 1. , 2. , 4. ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 1.,  4., 16., 64.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMRPXAdnFFdH",
        "outputId": "9ce61bab-fd14-4935-f9a4-fcf0e635d5ab"
      },
      "source": [
        "tf.exp(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
              "array([2.7182817e+00, 7.3890562e+00, 5.4598148e+01, 2.9809580e+03],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNmFNJ3hiO5I"
      },
      "source": [
        "We can also concatenate multiple tensors together, stacking them end-to-end to form a larger tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t771wC9giP1m",
        "outputId": "d4885666-4f28-49fb-f348-8c38deee1af4"
      },
      "source": [
        "X = tf.reshape(tf.range(12, dtype=tf.float32), (3, 4))\n",
        "Y = tf.constant([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "tf.concat([X, Y], axis=0), tf.concat([X, Y], axis=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(6, 4), dtype=float32, numpy=\n",
              " array([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.],\n",
              "        [ 2.,  1.,  4.,  3.],\n",
              "        [ 1.,  2.,  3.,  4.],\n",
              "        [ 4.,  3.,  2.,  1.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 8), dtype=float32, numpy=\n",
              " array([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
              "        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbiT-sHTEzqa"
      },
      "source": [
        "Sometimes, we want to construct a binary tensor via logical statements. Take X == Y as an example. For each position, if X and Y are equal at that position, the corresponding entry in the new tensor takes a value of 1, meaning that the logical statement X == Y is true at that position; otherwise that position takes 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-2r0eI-h7aJ",
        "outputId": "4f1bfaf3-07fa-43a5-aab0-1170a0aa25af"
      },
      "source": [
        "X == Y"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=bool, numpy=\n",
              "array([[False,  True, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False]])>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLW3ildFibT9"
      },
      "source": [
        "# Broadcasting Mechanism\n",
        "\n",
        "Under certain conditions, when shapes differ, we can still perform elementwise operations by invoking the broadcasting mechanism. This mechanism works in the following way: First, expand one or both arrays by copying elements appropriately so that after this transformation, the two tensors have the same shape. Second, carry out the elementwise operations on the resulting arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWxn3E8plIOr",
        "outputId": "24f2ed76-bd7b-4db6-b5a2-c31677507dbb"
      },
      "source": [
        "a = tf.reshape(tf.range(3), (3, 1))\n",
        "b = tf.reshape(tf.range(2), (1, 2))\n",
        "a, b"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\n",
              " array([[0],\n",
              "        [1],\n",
              "        [2]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[0, 1]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SRryKjBlWeY"
      },
      "source": [
        "Since a and b are  3Ã—1  and  1Ã—2  matrices respectively, their shapes do not match up if we want to add them. We broadcast the entries of both matrices into a larger  3Ã—2  matrix as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M4Sw-9ulbPp",
        "outputId": "69756d55-e474-44f6-d215-4eb35857596e"
      },
      "source": [
        "a + b"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[0, 1],\n",
              "       [1, 2],\n",
              "       [2, 3]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWcO6XAIvE6e"
      },
      "source": [
        "[Source for this excerpt](https://numpy.org/doc/stable/user/basics.broadcasting.html)\n",
        "\n",
        "\n",
        "When operating on two arrays, NumPy compares their shapes element-wise. Two dimensions are compatible when\n",
        "\n",
        "they are equal, or\n",
        "\n",
        "one of them is 1\n",
        "\n",
        "If these conditions are not met, a ValueError: operands could not be broadcast together exception is thrown, indicating that the arrays have incompatible shapes. The size of the resulting array is the size that is not 1 along each axis of the inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCbXL7MvnTui"
      },
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "To apply deep learning to solving real-world problems, we often begin with preprocessing raw data, rather than those nicely prepared data in the tensor format. Among popular data analytic tools in Python, the pandas package is commonly used.\n",
        "\n",
        "[Pandas documentation](https://pandas.pydata.org/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "uZcbpRoroNDV",
        "outputId": "b06a6516-a23d-43e2-f03c-789cdfd42527"
      },
      "source": [
        "## Reading the dataset\n",
        "\n",
        "# If pandas is not installed, just uncomment the following line:\n",
        "# !pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('train.csv')\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0   1          60       RL  ...        WD         Normal    208500\n",
              "1   2          20       RL  ...        WD         Normal    181500\n",
              "2   3          60       RL  ...        WD         Normal    223500\n",
              "3   4          70       RL  ...        WD        Abnorml    140000\n",
              "4   5          60       RL  ...        WD         Normal    250000\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnZyqecBo0vt"
      },
      "source": [
        "Handling Missing Values: NaN values are unknown or missing values.To handle missing data, typical methods include imputation and deletion, where imputation replaces missing values with substituted ones, while deletion ignores missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0iVTXTgpYTS"
      },
      "source": [
        "data.isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn6glEMnpmBX"
      },
      "source": [
        "Different datatypes require different ways of dealing with missing values.\n",
        "\n",
        "[Handling Missing Values in pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlBtFnvtpwJv"
      },
      "source": [
        "# Vectors\n",
        "\n",
        "A scalar is represented by a tensor with just one element. Vectors in ML problems represent examples from the dataset. In math notation, we will usually denote vectors as bold-faced, lower-cased letters (e.g., $\\textbf{x}$ ,  $\\textbf{y}$ , and  $\\textbf{z}$) .\n",
        "\n",
        "We can refer to any element of a vector by using a subscript. For example, we can refer to the  $i$th  element of  $x$  by  $x_i$ . Note that the element  $x_i$  is a scalar, so we do not bold-face the font when referring to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL9RAUiV5pcF",
        "outputId": "51f16fec-d549-487c-b025-0536f781deb6"
      },
      "source": [
        "x = tf.range(4)\n",
        "x\n",
        "print(x[3])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8eg-LJtGEx1"
      },
      "source": [
        "With the advent of deep learning, we usually work with extremely large datasets. Therefore, its important we write efficient code. One such technique is vectorization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKVRudW1Hl34"
      },
      "source": [
        "import numpy as np\n",
        "a=np.array([1,2,3,4,5])\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1crMoJiHyn3"
      },
      "source": [
        "import time\n",
        "a=np.random.rand(1000000)\n",
        "b=np.random.rand(1000000)\n",
        "\n",
        "#Vectorized version\n",
        "start=time.time()\n",
        "c=np.dot(a,b)\n",
        "end=time.time()\n",
        "print('Vectorized version '+str(end-start)+' ms')\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stsKbQvqIhN-"
      },
      "source": [
        "#Non vectorized version\n",
        "c=0\n",
        "start=time.time()\n",
        "for i in range(1000000):\n",
        "  c+=a[i] * b[i]\n",
        "end=time.time()\n",
        "print('Non vectorized version '+str(end-start)+' ms')\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1374V6JMDp"
      },
      "source": [
        "How many times longer does the non-vectorized version takes? Try checking the time for a nested loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCUjADocJQVo"
      },
      "source": [
        "You must have heard about GPUs(Graphics Processing Unit) and CPUs(Central Processing Unit (CPU)).Both GPU and CPU have parallelization instructions. They're sometimes called SIMD instructions. This stands for a single instruction multiple data. But what this basically means is that, if you use built-in functions such as this np.function or other tf.functions that don't require you explicitly implementing a for loop. It enables Python to take much better advantage of parallelism to do your computations much faster. And this is true both computations on CPUs and computations on GPUs.\n",
        "\n",
        "More information on this:\n",
        "[Difference between GPU and CPU](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYdf97LZNuqY"
      },
      "source": [
        "# Vectorizing Logistic Regression\n",
        "\n",
        "We know that in logistic regression we are claculating the predicted value for each example using the following function:\n",
        "\n",
        "$\\hat{y}$= $\\sigma(\\textbf{w}^Tx + b)$\n",
        "\n",
        "where $\\sigma(a) = \\frac{1}{(1+e^{-a})}$\n",
        "\n",
        "For a given example $i$, the loss function for a single instance is given by:\n",
        "\n",
        "$l^{i}(y^{(i)},\\hat{y}^{(i)})$ = $-(y^{(i)}\\space log\\hat{y}^{(i)} + (1-y^{i}) log(1-\\hat{y}^{(i)}))$\n",
        "\n",
        "Cost function for the entire data:\n",
        "\n",
        "$L(y,\\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} l^{i}(y^{(i)},\\hat{y}^{(i)})$\n",
        "\n",
        "The computation here requires the calculation of the $\\hat{y}$. Lets consider $a=(\\textbf{w}^Tx + b)$. This $a$ needs to be computed for every instance. Instead of using an explicit for loop, we can find the dot product of the feature vector and the transpose of the weight vector. The bias term (if it exists) can be added to each individual calculation via broadcasting. Resulting $A$ vector will be:\n",
        "\n",
        "$A=[a^{(1)},a^{(2)}...a^{(n)}]$\n",
        "\n",
        "This step can be completed in 1 line of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpRU_OcYWibj"
      },
      "source": [
        "**Steps in implementing gradient descent**\n",
        "\n",
        "You get input X\n",
        "- You compute $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(n-1)}, a^{(n)})$\n",
        "- You calculate the cost function: $L = -\\frac{1}{n}\\sum_{i=1}^{m}(y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)}))$\n",
        "\n",
        "\n",
        "Here are the two formulas you will be using (Try finding the derivative of the cost function with respect to the parameters): \n",
        "\n",
        "\n",
        "$$ \\frac{\\partial L}{\\partial w} = \\frac{1}{n}X(A-Y)^T$$\n",
        "$$ \\frac{\\partial L}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^n (a^{(i)}-y^{(i)})$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9RSDnH6XbAH"
      },
      "source": [
        "#Assuming you have a custom sigmoid function\n",
        "#A = sigmoid(np.dot(w.T,X) + b)\n",
        "#cost=-1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n",
        "#dw = np.dot(X, (A-Y).T)/n\n",
        "#db= np.sum(A-Y)/n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9BfEGVlrtxC"
      },
      "source": [
        "**The Update Step**\n",
        "\n",
        "Once you have initialized your parameters and you have computed a cost function and its gradient.Next, you want to update the parameters using gradient descent.\n",
        "\n",
        "Write down the optimization function. The goal is to learn  w  and  b  by minimizing the cost function  L . For a parameter  Î¸ , the update rule is  Î¸=Î¸âˆ’$\\eta$ dÎ¸ , where  $\\eta$  is the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsfFJOjzs-EB"
      },
      "source": [
        "#You basically need to write down two steps and iterate through them for the entire dataset:\n",
        "# 1) Calculate the cost and the gradient for the current parameters.\n",
        "# 2) Update the parameters using gradient descent rule for w and b.\n",
        "#w = w - learning_rate*dw\n",
        "#b= b - learning_rate*db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XksbSGhbtn-F"
      },
      "source": [
        "**Predict**\n",
        "The previous function/code will output the learned w and b. We are able to use w and b to predict the labels for a dataset X.Next step is prediction. There are two steps to computing predictions:\n",
        "\n",
        "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
        "\n",
        "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5) and store the predictions in a vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rek_NCalRKd"
      },
      "source": [
        "# Activation Functions\n",
        "\n",
        "The choice of activation functions is critical in a Neural Network(NN) Design. The logistic regression model we saw above is very similar to the perceptron which is a basic building block of any NN model. \n",
        "\n",
        "In problems where a binary class label needs to be predicted, usually sign function is can be a choice. For problems where the target variable to be predicted is real, it makes sense to use the identity activation function. When predicting probabilities of a binary class it makes sense to use the sigmoid function as it restricts the outcome between a 0-1 value.\n",
        "\n",
        "The importance of non-linear activation functions will become clear when we move to multi-layered architecture.\n",
        "\n",
        "[More about activation functions](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP5dfiNJlWbU"
      },
      "source": [
        "# Readings for Today\n",
        "\n",
        "[Paper 1](https://arxiv.org/pdf/1609.04747.pdf)\n",
        "\n",
        "[Paper 2](https://proceedings.neurips.cc/paper/2016/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoWo0V4b2h_P"
      },
      "source": [
        "# Extra Resources\n",
        "\n",
        "[Article](https://iamtrask.github.io/2015/07/27/python-network-part2/)"
      ]
    }
  ]
}