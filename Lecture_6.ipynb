{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNK62HT5ERz4OZBx134XdRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmamushtaque/CSCI4962-Projects-ML-AI/blob/main/Lecture_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDUThhqyzDhe"
      },
      "source": [
        "# Lecture 6\n",
        "\n",
        "# Topics for Today\n",
        "\n",
        "1. Issues to address when designing a ML/AI project\n",
        "2. Overall Issues/Strategy for a Deep Learning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF_Pi0iNCira"
      },
      "source": [
        "# Machine Learning Strategy\n",
        "\n",
        "Based on your first iteration through the model and getting results, you can decide on a number of updates to your models. Some of these can be:\n",
        "\n",
        "1. You want to collect more data\n",
        "2. You want to train your algorithm longer\n",
        "3. Try some optimization algorithm\n",
        "4. Use regularization\n",
        "5. Tune Hyperparameters\n",
        "\n",
        "\n",
        "There are efficient strategies that can help you move in the right direction. We will discuss a few of those in today's lecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kthY9fDeHzl"
      },
      "source": [
        "# Tuning ML Process (Orthogonalization)\n",
        "\n",
        "A typical ML process is:\n",
        "\n",
        "1. Fit training set on the cost function\n",
        "2. Fit dev set on the cost function\n",
        "3. Fit test set\n",
        "\n",
        "If the model performs well on all three steps then we are in an ideal world. Usually this is not the case, therefore we need to fine tune our model at each step. Each step has their own parameters to be tuned. \n",
        "\n",
        "For example if step 1 does not give a good result we may want to focus on getting more data or choosing a good optimization algorithm. \n",
        "\n",
        "In step 2 if we do not get good results, then we might need to use regularization. \n",
        "\n",
        "In step 3 the remedy could be to get a bigger dev set or maybe choose a different model. \n",
        "\n",
        "Thinking of these remedies but according to these 3 different directions is sometimes referred to as orthogonalization. Basically depending on the issue you are facing motivates your remedy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUT1_qybhZ71"
      },
      "source": [
        "# Evaluation Metric\n",
        "\n",
        "When selecting your evaluation metrics there are many aspects that must be taken into consideration.\n",
        "\n",
        "Sometimes selecting two evaluations metrics can be confusing for certain problems. For example Precision and Recall are defined in such a way that sometimes both have a trade-of. Therefore, for one model you might get a good result for one metric and vice versa. One way to deal with this situation is to come up with a single evaluation metric that would encompass both (or all of your metrics). In this case it could be F1 score which is a harmonic mean of Precision and Recall.\n",
        "\n",
        "Another, way of combining metrics could be to formulate an optimization problem. If model accuracy and runtime are important for your model, then you can constrain your model by solving the maximizing accuracy problem subject to some maximum runtime constraint. This is useful in large neural networks that are achieving high accuracy at the expense of very high runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4NVnlH9qBw_"
      },
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "The possible approaches for finding the optimal parameters are:\n",
        "\n",
        "1. Hand tuning (Trial and Error) - This is based on trial and error experiments and experience of the user, parameters are chosen.\n",
        "\n",
        "2. Grid Search - In this a grid is created based on parameter values. And then all possible parameter combinations is tried and and the best one is selected.\n",
        "\n",
        "3. Random Search - In this instead of trying all possible combinations as in Grid Search, only randomly selected subset of the parameters is tried and the best is chosen.\n",
        "\n",
        "4. Bayesian Optimization (Gausian Proces) - Gaussian Process uses a set of previously evaluated parameters and resulting accuracy to make an assumption about unobserved parameters. Acquisition Function using this information suggest the next set of parameters. [link](https://ekamperi.github.io/machine%20learning/2021/05/08/bayesian-optimization.html)\n",
        "\n",
        "\n",
        "5. Tree-structured Parzen Estimators (TPE) - Each iteration TPE collects new observation and at the end of the iteration, the algorithm decides which set of parameters it should try next. [link](https://medium.com/optuna/multivariate-tpe-makes-optuna-even-more-powerful-63c4bfbaebe2)\n",
        "\n",
        "One important aspect of hyperparameter tuning is that, in most search based methods the logarithms of the hyperparameters are sampled rather than the actual values. For example if searching for $\\eta$ between 0.1 and 0.001 we first sample $log\\eta$ uniformly between -1 and -3 and then exponentiate to the power of 10. However, there are certain parameters that are searched in the uniform space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTwSJ7UZsSEp"
      },
      "source": [
        "# Feature Preprocessing\n",
        "\n",
        "Feature pre-processing in neural networks is not very different from other ML models.\n",
        "\n",
        "1. *Additive Preprocessing and mean centering:* It is useful to mean center the data to remove any kind of bias from the model. Many algorithms like pCA work with the assumption of mean centered data. In practice a vector of column-wise means is subtracted from each data point.\n",
        "\n",
        "A similar type of preprocessing is done to get rid of negative values if it is desired. One way is to add the most negative entry to the rest of the values.\n",
        "\n",
        "2. *Feature Normalization:* A common practice is to divide each feature value by its standard deviation. When this scaling is combines with mean-centering, the data is said to be standardized. The basic idea is that the data is presumed to be drawn from a standard normal distribution with mean zero and unit variance.\n",
        "\n",
        "Another type of feature normalization is to compute the minimum and maximum value of any attribute. Next subtract the min value from the data point and divide it by the difference between max and min.\n",
        "\n",
        "Feature normalization ensures better performance as it is common for the relative values of features to vary more than an order of magnitude. By using these techniques we can lower the sensitivity of the learning algorithm for some features versus the others.\n",
        "\n",
        "3. *Whitening:* Whitening is a technique of creating a new set of de-correlated features. PCA (Principal Component Analysis) is used to achieve this. \n",
        "\n",
        "PCA can be thought of as the application of Singular Value Decomposition (SVD) after mean-centering a data matrix. if D is a $n X m$ mean centered Data matrix and C is a $n X n$ covariance matrix that gives the covariance\n",
        "between dimensions. Therefore, we can say that $C=(D^T D)/n$\n",
        "\n",
        "The eigenvectors of the covariance matrix provide de-correlated directions in the data. Eigenvalues provide variance along each of the directions. Therefore, if we use top-k eigenvectors (largest k eigenvalues) of the covariance matrix, most of the variance in the data will be retained and noise will be removed. One can choose some threshold eigenvalue when selecting these new dimensions.\n",
        "\n",
        "Let the final matrix be P which has dimensions $d X k$, where each column contains one of the top-k eigenvectors. The data matrix D can be transformed into the $k$ dimensional axis system by multiplying with the matrix P. the resulting matrix U will be $n X k$. The rows will contain transformed $n$ points. The variances of the columns of U are the corresponding eigenvalues (because this is the property of the de-correlating transformation of principal component analysis). In whitening each column of U is scaled to unit variance by dividing it with the standard deviation. the transformed features are fed into the neural network. This may change the architecture of the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtvXIteWeuoG"
      },
      "source": [
        "The basic idea behind whitening is that the data is assumed to be generated from an independent Gaussian distribution along each principal component. By whitening we assume that each such distribution is a standard normal distribution and each feature has equal importance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvOllLk5xuUx"
      },
      "source": [
        "# Initialization\n",
        "\n",
        "Initialization is more important in Neural Networks due to stability issues in the training process. Activation of each successive layer can either become weaker or stronger. This effect is exponentially related to the depth of the network and is particularly severe in Deep Networks. One way to deal with this issue is to choose good initialization points such that the gradients are stable across different layers.\n",
        "\n",
        "One possible way of generating values is to generate random values from a Gaussian Distribution with zero mean and a small standard devaition (usually estimated to be around $\\sqrt{1/r}$. Here $r$ is the number of inputs to that neuron for which the value is being picked. Bias neorons are always initialized to 0. Additionally weights are also initalized by sampling a value from the uniform distribution $[-\\sqrt{1/r},\\sqrt{1/r}]$.\n",
        "\n",
        "More on initialization: [link](https://www.deeplearning.ai/ai-notes/initialization/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsCBPjKhxxQM"
      },
      "source": [
        "# Vanishing and Exploding Gradient Problem\n",
        "\n",
        "In the backpropogation algorithm, we have the following updates:\n",
        "\n",
        "$dZ^{[l]} = dA^{[l]} *(g^{\\prime[l]} (Z^{[l]})) $\n",
        "\n",
        "$dW^{[l]}=dZ^{[l]}.dA^{[l-1]}$\n",
        "\n",
        "$db^{[l]} = dZ^{[l]} $\n",
        "\n",
        "$dA^{[l-1]}=W^{[l]}.dZ^{[l]}$\n",
        "\n",
        "Notice the recurrent relationship between gradients at each step. Let us assume we are using the sigmoid activation for a 0,1 output $f$. The derivative of $f$ is given by $f(1-f)$. the value takes on a maximum at $f=0.5$. Therefore, the value of $g^{\\prime[l]} (Z^{[l]}) $ is no more than 0.25 even at its maximum. The absolute value of weights is expected to be equal to one (we are considering one node network only), therefore each weight update will cause the value of $dZ^{[l]}$ to be 0.25 times that of $dZ^{[l+1]}$. So after moving $r$ layers the drop would be of the order of $0.25^r$. This example is a simplified version of what is known as the vanishing gradient problem.\n",
        "\n",
        "As the backpropagation algorithm advances downwards(or backward) from the output layer towards the input layer, the gradients often get smaller and smaller and approach zero which eventually leaves the weights of the initial or lower layers nearly unchanged. As a result, the gradient descent never converges to the optimum. \n",
        "\n",
        "One way of dealing with this problem could be to choose an activation with larger gradients or choosing the initial weights to be higher. if we go too far in doing this, we may get an opposite issue of exploding gradients.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7-vRDFASGen"
      },
      "source": [
        "# Solution to the gradient problem\n",
        "\n",
        "1. Initialization: In addition to the techniques listed above, here is a [link](http://proceedings.mlr.press/v15/glorot11a.html) to the paper that proposes a way to deal with this issue. For the proper flow of the signal, the authors argue that:\n",
        "\n",
        "  a. The variance of outputs of each layer should be equal to the variance of its inputs.\n",
        "\n",
        "  b. The gradients should have equal variance before and after flowing through a layer in the reverse direction.\n",
        "\n",
        "  Note: keras has a variance scaling initializer that is worth exploring.\n",
        "\n",
        "\n",
        "2. Choice of Activation Functions: We observed that the nature of sigmoid is saturating for larger inputs (negative or positive). This turned out to be a major reason behind the vanishing of gradients thus making it non-recommendable to use in the hidden layers of the network.\n",
        "\n",
        "So to tackle the issue regarding the saturation of activation functions like sigmoid and tanh, we must use some other non-saturating functions like ReLu and its alternatives.\n",
        "\n",
        "Relu(z) = max(0,z)\n",
        "\n",
        "Outputs 0 for any negative input.\n",
        "\n",
        "Range: [0, infinity]\n",
        "\n",
        "Unfortunately, the ReLu function is also not a perfect pick for the intermediate layers of the network “in some cases”. It suffers from a problem known as dying ReLus wherein some neurons just die out, meaning they keep on throwing 0 as outputs with the advancement in training.\n",
        "\n",
        "[Leaky Relu](https://cdn-images-1.medium.com/max/800/1*W6BURQnUE62qyxJxMDpdnA.png)\n",
        "\n",
        "LeakyReLUα(z) = max(αz, z)\n",
        "\n",
        "The amount of “leak” is controlled by the hyperparameter α, it is the slope of the function for z < 0.\n",
        "\n",
        "The smaller slope for the leak ensures that the neurons powered by leaky Relu never die; although they might venture into a state of coma for a long training phase they always have a chance to eventually wake up.\n",
        "α can also be trained, that is, the model learns the value of α during training. This variant wherein α is now considered a parameter rather than a hyperparameter is called parametric leaky ReLu (PReLU).\n",
        "\n",
        "\n",
        "3. Batch Normalization: [Link](https://arxiv.org/abs/1502.03167) \n",
        "\n",
        "The Following key points explain the intuition behind BN and how it works:\n",
        "\n",
        "  a. It consists of adding an operation in the model just before or after the activation function of each hidden layer.\n",
        "\n",
        "b. This operation simply zero-centers and normalizes each input, then scales and shifts the result using two new parameter vectors per layer: one for scaling, the other for shifting.\n",
        "\n",
        "c. The operation lets the model learn the optimal scale and mean of each of the layer’s inputs.\n",
        "\n",
        "d. To zero-center and normalize the inputs, the algorithm needs to estimate each input’s mean and standard deviation.\n",
        "\n",
        "e. It does so by evaluating the mean and standard deviation of the input over the current mini-batch (hence the name “Batch Normalization”).\n",
        "\n",
        "\n",
        "Standardizing the activations of the prior layer means that the assumptions the subsequent layer makes about the spread and distribution of inputs during the weight update will not change, at least not dramatically. This has the effect of stabilizing and speeding-up the training process of deep neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcNvYNFiyW2I"
      },
      "source": [
        "# Model Selection\n",
        "\n",
        "[link](https://machinelearningmastery.com/a-gentle-introduction-to-model-selection-for-machine-learning/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4QYM0VUah5I"
      },
      "source": [
        "# Readings\n",
        "\n",
        "[Paper 1](https://arxiv.org/pdf/1907.13359.pdf)"
      ]
    }
  ]
}