{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHxB//cIOJ3XXGBY7yBprj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmamushtaque/CSCI4962-Projects-ML-AI/blob/main/Lecture_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBDQJEuiViV1"
      },
      "source": [
        "# Lecture 9\n",
        "\n",
        "# Today's Topics\n",
        "\n",
        "1. Sequence to sequence models\n",
        "2. Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_ZvFNlxHRCx"
      },
      "source": [
        "# Sequence to Sequence Models\n",
        "\n",
        "Models for machine translation require the entire sequence to be translated to another sequence.\n",
        "\n",
        "There are many architectures for this task:\n",
        "\n",
        "1. Statistical machine translation, or SMT for short, is the use of statistical models that learn to translate text from a source language to a target language gives a large corpus of examples.\n",
        "\n",
        "This task of using a statistical model can be stated formally as follows:\n",
        "\n",
        "Given a sentence T in the target language, we find the sentence S from which the translator produced T. We know that our chance of error is minimized by choosing that sentence S that is most probable given T. Thus, we wish to choose S so as to maximize Pr(S|T)\n",
        "\n",
        "2. The encoder-decoder architecture for recurrent neural networks is the standard neural machine translation method that rivals and in some cases outperforms classical statistical machine translation methods.\n",
        "\n",
        "Multilayer Perceptron neural network models can be used for machine translation, although the models are limited by a fixed-length input sequence where the output must be the same length.\n",
        "\n",
        "These early models have been greatly improved upon recently through the use of recurrent neural networks organized into an encoder-decoder architecture that allow for variable length input and output sequences.\n",
        "\n",
        "\n",
        "\n",
        "[Source](https://arxiv.org/abs/1409.3215)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRGlUMwBfL9x"
      },
      "source": [
        "# Beam Search Decoder for Natural language Processing\n",
        "\n",
        "Natural language processing tasks, such as caption generation and machine translation, involve generating sequences of words.\n",
        "\n",
        "Models developed for these problems often operate by generating probability distributions across the vocabulary of output words and it is up to decoding algorithms to sample the probability distributions to generate the most likely sequences of words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMJrTwe93LZt"
      },
      "source": [
        "# Metric for Measuring Machine Translation Quality\n",
        "\n",
        "BLEU (BiLingual Evaluation Understudy) is a metric for automatically evaluating machine-translated text. The BLEU score is a number between zero and one that measures the similarity of the machine-translated text to a set of high quality reference translations. A value of 0 means that the machine-translated output has no overlap with the reference translation (low quality) while a value of 1 means there is perfect overlap with the reference translations (high quality).\n",
        "\n",
        "It has been shown that BLEU scores correlate well with human judgment of translation quality. Note that even human translators do not achieve a perfect score of 1.0.\n",
        "\n",
        "[Source: Google Cloud](https://cloud.google.com/translate/automl/docs/evaluate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-vlM8Ur3s-a"
      },
      "source": [
        "# Attention Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KajEZv1g3wkU"
      },
      "source": [
        "# Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-Xa4YR33zNP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbohAleY3zj7"
      },
      "source": [
        "# Transformer Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWH7gA5cWYXT"
      },
      "source": [
        "# Readings\n",
        "\n",
        "[Paper 1](https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf)\n",
        "\n",
        "[Paper 2](https://arxiv.org/pdf/1406.1078.pdf?source=post_page---------------------------)"
      ]
    }
  ]
}